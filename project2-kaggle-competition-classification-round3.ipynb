{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90936,"databundleVersionId":10665762,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n\n#### Maximum Points: 100\n\n<div>\n    <table>\n        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n    </table>\n</div>\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport time\nfrom dataclasses import dataclass\nfrom typing import List, Union, Tuple\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom torchvision import datasets, transforms\n\nfrom torchmetrics import MeanMetric\nfrom torchmetrics.classification import MulticlassAccuracy\n\n\n\n# Text formatting\nbold = \"\\033[1m\"\nend = \"\\033[0m\"\n\nplt.style.use('ggplot')\nblock_plot=False\n\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T23:58:58.383140Z","iopub.execute_input":"2025-02-15T23:58:58.383479Z","iopub.status.idle":"2025-02-15T23:59:18.286988Z","shell.execute_reply.started":"2025-02-15T23:58:58.383445Z","shell.execute_reply":"2025-02-15T23:59:18.285983Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Compulsary Preprocessing Transforms","metadata":{}},{"cell_type":"code","source":"def image_preprocess_transforms(img_size):\n    preprocess = transforms.Compose(\n        [\n            transforms.Resize(img_size),\n            transforms.ToTensor(),\n        ]\n    )\n\n    return preprocess","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <font style=\"color:blue\"> Common Image Transforms","metadata":{}},{"cell_type":"code","source":"def image_common_transforms(img_size=(224, 224), mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n    preprocess = image_preprocess_transforms(img_size)\n\n    common_transforms = transforms.Compose(\n        [\n            preprocess,\n            transforms.Normalize(mean, std),\n        ]\n    )\n\n    return common_transforms","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <font style=\"color:blue\"> Mean and STD\n\nFunction for Calculating Mean and Variance.","metadata":{}},{"cell_type":"code","source":"def get_mean_std(data_root, img_size=(224, 224), num_workers=4):\n    transform = image_preprocess_transforms(img_size=img_size)\n\n    loader = data_loader(data_root, transform)\n\n    batch_mean = torch.zeros(3)\n    batch_mean_sqrd = torch.zeros(3)\n\n    for batch_data, _ in loader:\n        batch_mean += batch_data.mean(dim=(0, 2, 3))  # E[batch_i]\n        batch_mean_sqrd += (batch_data**2).mean(dim=(0, 2, 3))  #  E[batch_i**2]\n\n    # E[dataset] = E[E[batch_1], E[batch_2], ...]\n    mean = batch_mean / len(loader)\n\n    # var[X] = E[X**2] - E[X]**2\n\n    # E[X**2] = E[E[batch_1**2], E[batch_2**2], ...]\n    # E[X]**2 = E[E[batch_1], E[batch_2], ...] ** 2\n\n    var = (batch_mean_sqrd / len(loader)) - (mean**2)\n\n    std = var**0.5\n    print(\"mean: {}, std: {}\".format(mean, std))\n\n    return mean, std","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n\nIn this section, you have to write a class or methods, which will be used to get training and validation data loader.\n\nYou need to write a custom dataset class to load data.\n\n**Note; There is   no separate validation data. , You will thus have to create your own validation set, by dividing the train data into train and validation data. Usually, we do 80:20 ratio for train and validation, respectively.**\n\n\nFor example:\n\n```python\nclass KenyanFood13Dataset(Dataset):\n    \"\"\"\n    \n    \"\"\"\n    \n    def __init__(self, *args):\n    ....\n    ...\n    \n    def __getitem__(self, idx):\n    ...\n    ...\n    \n\n```\n\n\n```python\ndef get_data(args1, *args):\n    ....\n    ....\n    return train_loader, test_loader\n```","metadata":{}},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Data Loader for Full Data\n\nData loader for generating batches of data to be used by the training routine","metadata":{}},{"cell_type":"code","source":"def data_loader(data_root, transform, batch_size=16, shuffle=False, num_workers=2):\n    dataset = datasets.ImageFolder(root=data_root, transform=transform)\n\n    loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        shuffle=shuffle,\n    )\n\n    return loader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Prepare Data\n\nThe main function which uses all the above functions to generate the train and valid dataloaders.","metadata":{}},{"cell_type":"code","source":"def get_data(batch_size, data_root, img_size=(224, 224), num_workers=4, data_augmentation=False):\n    \"\"\"\n    Loads training and validation datasets with appropriate transformations.\n\n    Parameters:\n        batch_size (int): Number of samples per batch.\n        data_root (str): Path to the dataset root directory.\n        img_size (tuple): Image size (height, width).\n        num_workers (int): Number of workers for data loading.\n        data_augmentation (bool): Whether to apply data augmentation.\n\n    Returns:\n        tuple: (train_loader, valid_loader)\n    \"\"\"\n\n    # Paths for training and validation datasets\n    train_data_path = os.path.join(data_root, \"Train\")\n    valid_data_path = os.path.join(data_root, \"Valid\")\n\n    # Compute dataset-specific mean and std for normalization\n    mean, std = get_mean_std(train_data_path, img_size=img_size, num_workers=num_workers)\n\n    # Common transforms (applied to both train and validation data)\n    common_transforms = image_common_transforms(img_size, mean, std)\n\n    # Data augmentation for training data (optional)\n    if data_augmentation:\n        train_transforms = transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomRotation(degrees=15),\n            transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            common_transforms  # Apply normalization at the end\n        ])\n    else:\n        train_transforms = common_transforms\n\n    # Load training data\n    train_loader = data_loader(\n        train_data_path,\n        transform=train_transforms,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers\n    )\n\n    # Load validation data (no augmentation)\n    valid_loader = data_loader(\n        valid_data_path,\n        transform=common_transforms,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers\n    )\n\n    return train_loader, valid_loader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">2. Configuration [5 Points]</font>\n\n**Define your configuration here.**\n\nFor example:\n\n\n```python\n@dataclass\nclass TrainingConfiguration:\n    '''\n    Describes configuration of the training process\n    '''\n    batch_size: int = 10 \n    epochs_count: int = 50  \n    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n    log_interval: int = 5  \n    test_interval: int = 1  \n    data_root: str = \"/kaggle/input/opencv-pytorch-project-2-classification-round-3\" \n    num_workers: int = 2  \n    device: str = 'cuda'  \n    \n```","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n\n**Define methods or classes that will be used in model evaluation. For example, accuracy, f1-score etc.**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n\n\n**Write the methods or classes to be used for training and validation.**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">5. Model [5 Points]</font>\n\n**Define your model in this section.**\n\n**You are allowed to use any pre-trained model.**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">6. Utils [5 Points]</font>\n\n**Define those methods or classes, which have  not been covered in the above sections.**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">7. Experiment [5 Points]</font>\n\n**Choose your optimizer and LR-scheduler and use the above methods and classes to train your model.**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">8. TensorBoard Log Link [5 Points]</font>\n\n**Share your TensorBoard scalars logs link here You can also share (not mandatory) your GitHub link, if you have pushed this project in GitHub.**\n\n\nNote: In light of the recent shutdown of tensorboard.dev, we have updated the submission requirements for your project. Instead of sharing a tensorboard.dev link, you are now required to upload your generated TensorBoard event files directly onto the lab. As an alternative, you may also include a screenshot of your TensorBoard output within your Jupyter notebook. This adjustment ensures that your data visualization and model training efforts are thoroughly documented and accessible for evaluation.\n\nYou are also welcome (and encouraged) to utilize alternative logging services like wandB or comet. In such instances, you can easily make your project logs publicly accessible and share the link with others.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n\n**Share your Kaggle profile link  with us here to score , points in  the competition.**\n\n**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n\n\n**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, to get evaluated for  this section.**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}